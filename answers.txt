Answers to the text questions go here.

1d. The Flesch-Kincaid score is not a valid, robust, or reliable measure of text difficulty under two key conditions.
First, it performs poorly when applied to literary forms it was not designed to assess, such as poetry, plays, or fiction. The formula was developed for educational textbooks, so its reliance on word and sentence length leads to inaccurate results for stylised writing. For example, Shakespeare’s sonnets or Dr Seuss’s The Cat in the Hat may receive misleading scores, as their structures deviate from textbook prose.
Second, the score fails to account for conceptual complexity or prior knowledge required. It measures surface-level features (e.g., syllables per word, sentence length) but ignores deeper comprehension barriers. A horror novel with polysyllabic words may score as "difficult" yet remain more accessible than a concise mathematics paper with technical jargon. Similarly, a short sentence containing a term like "noumenon" could be harder to grasp than a longer one with familiar vocabulary.
So, while useful for straightforward texts, Flesch-Kincaid lacks validity when evaluating specialised, creative, or conceptually dense material.
 

2f. Explain the tokenizer function: 
This custom tokeniser is a sophisticated, complex preprocessing tool specifically designed for analysing British political discourse. The function transforms raw parliamentary debates into a structured set of meaningful tokens that preserve the linguistic and ideological nuance of UK politics. Standard NLP methods often fail to capture these subtleties, treating terms like “Brexit”, “levelling up” or “red wall” as generic words with no special political connotation. This tokeniser addresses that by explicitly recognising and preserving such expressions. 
The pipeline begins by cleaning the text of procedural noise, removing stage directions such as “[applause]” and verbal fillers like “erm” or “you know”, ensuring that the analysis focuses on substantive content.  The function then performs a domain-specific normalisation step using a set of regular expression rules defined in a JSON configuration file. This step standardises political terms by expanding acronyms like “PMQs” into “prime minister's questions” and converting informal references such as “Tories” into their formal equivalents like “conservative party”. 
Next, named entities, such as politicians, institutions and locations, are accurately identified through spaCy’s named entity recognition and are preserved in the final output. The tokeniser also applies lemmatisation to reduce words to their base forms and filters the text to retain only the parts of speech most relevant for classification: nouns, verbs, adjectives and proper nouns. A dual-text approach ensures that named entities are extracted from the original unmodified text while the main tokenisation is applied to a cleaned and normalised version. 
Then, the tokeniser protects hyphenated compounds and political multi-word expressions by temporarily replacing hyphens with underscores and using curated lists of political phrases and vocabulary to ensure these expressions remain intact during processing. For instance, phrases like “cost of living” and “House of Commons” are preserved as single tokens such as “cost_of_living”. The tool also generates bigrams and trigrams to capture important collocations like “public services”, “green new deal” or “housing crisis”, which are critical for understanding political rhetoric and policy framing. 
Next, a carefully managed stopword filtering process removes generic and non-discriminative words while retaining politically salient pronouns such as “we”, “our” and “they”, which are often markers of collective identity or opposition. The output is a set of deduplicated, lowercase tokens in a standardised format using underscores to join multi-word expressions. This tokeniser is also able to disambiguate context-sensitive terms, for example, distinguishing “labour” as a political party from “labour” in the context of work through part-of-speech tagging and political dictionaries. 
Overall, this approach seeks to significantly enhance classification performance by filtering out irrelevant language while retaining and enriching the features that best represent party positions, ideological divides and political intent. The intended result is a high-quality, context-aware vocabulary ideally suited to machine learning tasks focused on the automated analysis of British political text.

Discuss its performance:
